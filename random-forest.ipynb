{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 4: Random Forest Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "%matplotlib inline\n",
    "\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Loans Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_compound</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137523</td>\n",
       "      <td>0.147592</td>\n",
       "      <td>0.137250</td>\n",
       "      <td>0.147503</td>\n",
       "      <td>0.147503</td>\n",
       "      <td>5.807410e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.147533</td>\n",
       "      <td>0.150140</td>\n",
       "      <td>0.145410</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>5.870094e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.147140</td>\n",
       "      <td>0.154775</td>\n",
       "      <td>0.145258</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>7.570041e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074822</td>\n",
       "      <td>0.153803</td>\n",
       "      <td>0.171586</td>\n",
       "      <td>0.151741</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>1.791359e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.165606</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.153709</td>\n",
       "      <td>0.158405</td>\n",
       "      <td>0.158405</td>\n",
       "      <td>1.190116e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_compound      Open      High       Low     Close  Adj Close  \\\n",
       "0        0.000000  0.137523  0.147592  0.137250  0.147503   0.147503   \n",
       "1        0.109560  0.147533  0.150140  0.145410  0.147141   0.147141   \n",
       "2        0.109560  0.147140  0.154775  0.145258  0.153770   0.153770   \n",
       "3        0.074822  0.153803  0.171586  0.151741  0.165578   0.165578   \n",
       "4        0.193133  0.165606  0.169145  0.153709  0.158405   0.158405   \n",
       "\n",
       "         Volume  \n",
       "0  5.807410e+08  \n",
       "1  5.870094e+08  \n",
       "2  7.570041e+08  \n",
       "3  1.791359e+09  \n",
       "4  1.190116e+09  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"..\\Group4\\sentiment_closing.csv\")\n",
    "df_sentiment_closing = pd.read_csv(file_path)\n",
    "df_sentiment_closing.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137523</td>\n",
       "      <td>0.147592</td>\n",
       "      <td>0.137250</td>\n",
       "      <td>0.147503</td>\n",
       "      <td>0.147503</td>\n",
       "      <td>5.807410e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147533</td>\n",
       "      <td>0.150140</td>\n",
       "      <td>0.145410</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>5.870094e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147140</td>\n",
       "      <td>0.154775</td>\n",
       "      <td>0.145258</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>7.570041e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.153803</td>\n",
       "      <td>0.171586</td>\n",
       "      <td>0.151741</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>1.791359e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165606</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.153709</td>\n",
       "      <td>0.158405</td>\n",
       "      <td>0.158405</td>\n",
       "      <td>1.190116e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close        Volume\n",
       "0  0.137523  0.147592  0.137250  0.147503   0.147503  5.807410e+08\n",
       "1  0.147533  0.150140  0.145410  0.147141   0.147141  5.870094e+08\n",
       "2  0.147140  0.154775  0.145258  0.153770   0.153770  7.570041e+08\n",
       "3  0.153803  0.171586  0.151741  0.165578   0.165578  1.791359e+09\n",
       "4  0.165606  0.169145  0.153709  0.158405   0.158405  1.190116e+09"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features set\n",
    "X = df_sentiment_closing.copy()\n",
    "X.drop(\"title_compound\", axis=1, inplace=True)\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the target vector `y` before scaling the data, the `ravel` method is used instead of `reshape` as we did in the decision tree demo.\n",
    "\n",
    "Reshape can also be used. As long as you pass in one of `lists, numpy arrays, scipy-sparse matrices or pandas dataframes`. Refer to `sklearn` docs for `train_test_split` - see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Upon further testing, it is worth noting that `y = df_loans[\"bad\"]` is also sufficient as an input, which is a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16344/1750070918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define target vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sentiment_closing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title_compound\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# y = df_sentiment_closing[\"title_compound\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# y = df_sentiment_closing[\"title_compound\"].values.reshape(-1,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reval'"
     ]
    }
   ],
   "source": [
    "# Define target vector\n",
    "y = df_sentiment_closing[\"title_compound\"].reval()\n",
    "# y = df_sentiment_closing[\"title_compound\"]\n",
    "# y = df_sentiment_closing[\"title_compound\"].values.reshape(-1,1)\n",
    "y[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount                            1.0\n",
       "term                              1.0\n",
       "age                               1.0\n",
       "month_num                         1.0\n",
       "education_Bachelor                1.0\n",
       "education_High School or Below    1.0\n",
       "education_Master or Above         1.0\n",
       "education_college                 1.0\n",
       "gender_female                     1.0\n",
       "gender_male                       1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm scaled values...for fun\n",
    "df_X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "round(df_X_train_scaled.mean(), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount                            1.0\n",
       "term                              1.0\n",
       "age                               1.0\n",
       "month_num                         1.0\n",
       "education_Bachelor                1.0\n",
       "education_High School or Below    1.0\n",
       "education_Master or Above         1.0\n",
       "education_college                 1.0\n",
       "gender_female                     1.0\n",
       "gender_male                       1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_X_train_scaled.std(), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the random forest instance is created, there are two important parameters to set:\n",
    "\n",
    "- `n_estimators`: This is the number of random forests to be created by the algorithm. In general, a higher number makes the predictions stronger and more stable. However, a very large number can result in higher training time. A good approach is to start low and increase the number if the model performance is not adequate.\n",
    "- `random_state`: This parameter defines the seed used by the random number generator. It is important to define a random state when comparing multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the random forest model is created, it is fitted with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, some predictions are made using the scaled testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions Using the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the model, a confusion matrix, the `accuracy_score`, and the `classification_report` from `sklearn.metrics` are used.\n",
    "\n",
    "The confusion matrix is created using the `y_test` and the `results` vectors. The matrix shows how well the model predicts fraudulent loan applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the results, it can be concluded that this model may not be the best one for preventing fraudulent loan applications. Now there are several strategies that may improve this model, such as:\n",
    "\n",
    "- Reducing the number of features using principal component analysis (PCA).\n",
    "\n",
    "- Creating new features based on new data from the problem domain.\n",
    "\n",
    "- Increasing the number of estimators and/or general hyperparameter tuning and cross validation. See https://www.datasciencelearner.com/how-to-improve-accuracy-of-random-forest-classifier/.\n",
    "\n",
    "Finally, explain to students that a byproduct of the random forest algorithm is a ranking of feature importance (i.e., which features have the most impact on the decision).\n",
    "\n",
    "The `RandomForestClassifier` of `sklearn` provides an attribute called `feature_importances_`, where you can see which features were the most significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the features by importance\n",
    "importances_df = pd.DataFrame(sorted(zip(rf_model.feature_importances_, X.columns), reverse=True))\n",
    "importances_df.set_index(importances_df[1], inplace=True)\n",
    "importances_df.drop(columns=1, inplace=True)\n",
    "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)\n",
    "importances_sorted = importances_df.sort_values(by='Feature Importances')\n",
    "importances_sorted.plot(kind='barh', color='lightgreen', title= 'Features Importances', legend=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this demo, it can be seen that the `age` of the person and the `month` of the loan application are the more relevant features.\n",
    "\n",
    "- If we need to drop some features, analyzing feature importance could help to decide which features can be removed."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
